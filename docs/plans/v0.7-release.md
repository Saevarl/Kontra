# v0.7 Release Plan

Target: Open source release

## Features

1. **`storage_options`** — Cloud credential passing (must-have)
2. **Custom SQL pushdown** — Execute `custom_sql_check` on remote databases
3. **`kontra history`** — CLI to query validation history

---

## 1. `storage_options` Parameter

### What It Does

Pass cloud storage credentials explicitly instead of relying on environment variables:

```python
# Current (env vars only)
kontra.validate("s3://bucket/data.parquet", rules=[...])

# Proposed
kontra.validate(
    "s3://bucket/data.parquet",
    storage_options={"aws_access_key_id": "...", "aws_secret_access_key": "..."},
    rules=[...]
)
```

### Why It Matters

- Lambda/Kubernetes: Can't always set env vars
- Multi-tenant: Different buckets need different credentials
- Dynamic credentials: Fetched from secrets manager at runtime
- Standard pattern: Matches Polars/pandas ecosystem

### Supported Sources

| Source | URI Prefix | Credentials |
|--------|------------|-------------|
| S3 | `s3://` | `aws_access_key_id`, `aws_secret_access_key`, `aws_session_token`, `region` |
| MinIO (S3-compatible) | `s3://` | Same as S3 + `endpoint_url` |
| Azure ADLS | `abfss://`, `az://` | `account_name`, `account_key`, `sas_token`, `tenant_id`, `client_id`, `client_secret` |
| GCS | `gs://` | `service_account_key` (JSON string or path) |

### Current State (Important)

**The existing S3 connector has only been tested with MinIO, not actual AWS S3.**

Current implementation reads from env vars:
- `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY` — credentials
- `AWS_ENDPOINT_URL` — custom endpoint (MinIO)
- `AWS_REGION` — region (AWS)

Key difference between MinIO and AWS S3:
- **MinIO**: Requires `endpoint_url` (e.g., `http://localhost:9000`)
- **AWS S3**: No endpoint_url, uses default AWS endpoints, requires `region`

The `storage_options` implementation must work for BOTH:

```python
# MinIO (tested, working)
storage_options={
    "aws_access_key_id": "minioadmin",
    "aws_secret_access_key": "minioadmin",
    "aws_region": "us-east-1",  # Required by Polars, use us-east-1 for MinIO
    "endpoint_url": "http://localhost:9000",
}

# AWS S3 (not tested yet)
storage_options={
    "aws_access_key_id": "AKIA...",
    "aws_secret_access_key": "...",
    "aws_region": "us-east-1",
}
```

**Polars storage_options keys** (from [Polars docs](https://docs.pola.rs/user-guide/io/cloud-storage/)):
- `aws_access_key_id` — credentials
- `aws_secret_access_key` — credentials
- `aws_region` — region (required, Polars infers if missing but fails on closed networks)
- `endpoint_url` — custom endpoint for S3-compatible storage

**Testing Strategy**:
1. Unit tests mock Polars calls, verify `storage_options` passed through correctly
2. Integration test with MinIO (local Docker, CI)
3. Manual test with real AWS S3 (or find someone with account to verify)

### Design Decisions

1. **Pass-through to Polars**: Don't reinvent — Polars already handles `storage_options`
2. **No validation**: We don't validate credentials, Polars/fsspec will error if wrong
3. **Optional parameter**: `None` means use env vars (current behavior)
4. **Profile too**: `kontra.profile()` also needs `storage_options`

### Files to Modify

| File | Changes |
|------|---------|
| `src/kontra/__init__.py` | Add `storage_options` param to `validate()`, `profile()` |
| `src/kontra/engine/engine.py` | Pass `storage_options` to materializers |
| `src/kontra/engine/materializers/duckdb.py` | Pass to `pl.scan_parquet()`, `pl.scan_csv()` |
| `src/kontra/scout/profiler.py` | Add `storage_options` param, pass to data loading |
| `src/kontra/cli/main.py` | Add `--storage-options` flag (JSON string) |
| `docs/python-api.md` | Document the parameter |
| `docs/getting-started.md` | Add example for cloud sources |

### Implementation Steps

- [ ] Add `storage_options: Optional[Dict[str, Any]] = None` to `validate()` signature
- [ ] Add `storage_options` to `profile()` signature
- [ ] Pass through `ValidationEngine` to materializers
- [ ] Update `DuckDBMaterializer` to use `storage_options` in Polars calls
- [ ] Add CLI `--storage-options '{"key": "value"}'` flag
- [ ] Write tests with mocked S3 (or skip if no credentials)
- [ ] Update docs

### Testing

```python
def test_storage_options_passed_to_polars(mocker):
    """Verify storage_options reaches Polars scan functions."""
    mock_scan = mocker.patch("polars.scan_parquet")

    kontra.validate(
        "s3://bucket/data.parquet",
        storage_options={"aws_access_key_id": "test"},
        rules=[rules.min_rows(1)]
    )

    mock_scan.assert_called_once()
    call_kwargs = mock_scan.call_args[1]
    assert call_kwargs["storage_options"]["aws_access_key_id"] == "test"
```

### Estimated Effort

**Low-medium** (half day to full day)

---

## 2. Custom SQL Pushdown to Remote Databases

### What It Does

Execute `custom_sql_check` SQL directly on the source database instead of loading data into DuckDB:

```yaml
# Contract
datasource: postgres:///public.orders

rules:
  - name: custom_sql_check
    params:
      sql: "SELECT COUNT(*) FROM {table} WHERE balance < 0 AND status = 'active'"
```

**Current behavior**: Load all data from PostgreSQL → DuckDB → Execute SQL
**Proposed behavior**: Execute SQL directly on PostgreSQL

### Why It Matters

- **Performance**: No data transfer for simple aggregations
- **Capability**: Use database-specific functions (PostGIS, JSON operators)
- **Resource**: Don't OOM loading 100M rows to check one condition

### Design Decisions

1. **Dialect detection**: Reuse existing connection type detection
2. **`{table}` placeholder**: Replace with fully qualified table name per dialect
3. **Result format**: Must return single integer (count of violations)
4. **Fallback**: If remote execution fails, fall back to current DuckDB behavior
5. **Security**: User-provided SQL — document that this runs on production DBs

### Supported Databases

| Database | Detection | Table Placeholder |
|----------|-----------|-------------------|
| PostgreSQL | `postgres://` URI or psycopg connection | `"schema"."table"` |
| SQL Server | `mssql://` URI or pyodbc connection | `[schema].[table]` |
| DuckDB | File sources (Parquet, CSV) | `{table}` as-is |

### SQL Execution Flow

```
custom_sql_check rule
        ↓
    Is source a remote database?
        ↓ Yes                    ↓ No
    Execute SQL on source    Execute via DuckDB (current)
        ↓
    Parse result (must be single int)
        ↓
    Return RuleResult
```

### Files to Modify

| File | Changes |
|------|---------|
| `src/kontra/rules/builtin/custom_sql_check.py` | Add `to_remote_sql()` method |
| `src/kontra/engine/executors/postgres_sql.py` | Handle `custom_sql_check` kind |
| `src/kontra/engine/executors/sqlserver_sql.py` | Handle `custom_sql_check` kind |
| `src/kontra/engine/engine.py` | Route `custom_sql_check` to remote executor |
| `tests/test_custom_sql_pushdown.py` | New test file |
| `docs/rules.md` | Document remote execution behavior |

### Implementation Steps

- [ ] Add `supports_remote_execution()` method to `CustomSqlCheckRule`
- [ ] Add `to_remote_sql(dialect, table_ref)` method to generate dialect-specific SQL
- [ ] Modify PostgreSQL executor to handle `custom_sql_check`
- [ ] Modify SQL Server executor to handle `custom_sql_check`
- [ ] Add routing logic in engine to detect remote-capable rules
- [ ] Add fallback to DuckDB if remote execution fails
- [ ] Write integration tests with PostgreSQL
- [ ] Update docs with remote execution notes

### Table Reference Handling

```python
def format_table_ref(self, dialect: str, schema: str, table: str) -> str:
    """Format table reference for SQL dialect."""
    if dialect == "postgresql":
        return f'"{schema}"."{table}"'
    elif dialect == "sqlserver":
        return f"[{schema}].[{table}]"
    else:
        return f"{schema}.{table}"
```

### Error Handling

```python
try:
    result = execute_remote_sql(conn, sql)
except Exception as e:
    logger.warning(f"Remote SQL execution failed: {e}, falling back to DuckDB")
    return execute_via_duckdb(sql)
```

### Testing

```python
@pytest.mark.integration
def test_custom_sql_pushdown_postgres(postgres_conn):
    """Verify custom_sql_check executes on PostgreSQL directly."""
    result = kontra.validate(
        postgres_conn,
        table="public.orders",
        rules=[
            rules.custom_sql_check(
                sql="SELECT COUNT(*) FROM {table} WHERE amount < 0"
            )
        ]
    )
    # Verify it didn't load data (check query log or mock)
```

### Security Considerations

Document clearly:
- User-provided SQL executes on production databases
- No sandboxing or SQL parsing
- User responsible for SQL injection risks in dynamic SQL
- Recommend parameterized queries where possible

### Estimated Effort

**Medium** (1-2 days)

---

## 3. `kontra history` CLI Command

### What It Does

Query validation history from state storage:

```bash
$ kontra history users.yml --since 7d

Contract: users.yml
Fingerprint: abc123

Run ID      Timestamp            Passed  Failed  Total Rows
──────────────────────────────────────────────────────────
run_a1b2    2026-01-22 14:30:00  Yes     0       10,000
run_c3d4    2026-01-21 09:15:00  No      142     10,000
run_e5f6    2026-01-20 11:45:00  No      89      9,850
run_g7h8    2026-01-19 16:00:00  Yes     0       9,800
```

### Why It Matters

- **Visibility**: See validation trends without external tools
- **Debugging**: "When did this start failing?"
- **Demos**: Show Kontra tracks history out of the box

### Design Decisions

1. **Source**: Query existing state backend (local, S3, PostgreSQL)
2. **Output formats**: Rich table (default), JSON (`-o json`)
3. **Filters**: `--since` (time), `--limit` (count), `--failed-only`
4. **No interpretation**: Just show data, no "drift detected" messages

### CLI Interface

```bash
kontra history <contract.yml> [OPTIONS]

Options:
  --since TEXT      Time filter: "24h", "7d", "2026-01-15" [default: 30d]
  --limit INTEGER   Maximum runs to show [default: 20]
  --failed-only     Only show failed runs
  --env TEXT        Environment to use
  -o, --output TEXT Output format: table, json [default: table]
```

### Output Formats

**Table (default)**:
```
Run ID      Timestamp            Passed  Failed  Total Rows
──────────────────────────────────────────────────────────
run_a1b2    2026-01-22 14:30:00  Yes     0       10,000
```

**JSON**:
```json
{
  "contract": "users.yml",
  "fingerprint": "abc123",
  "runs": [
    {
      "run_id": "run_a1b2",
      "timestamp": "2026-01-22T14:30:00",
      "passed": true,
      "failed_count": 0,
      "total_rows": 10000
    }
  ]
}
```

### Files to Modify

| File | Changes |
|------|---------|
| `src/kontra/cli/main.py` | Add `history` command |
| `src/kontra/state/backends/base.py` | Add `get_history()` method to base class |
| `src/kontra/state/backends/local.py` | Implement `get_history()` |
| `src/kontra/state/backends/postgres.py` | Implement `get_history()` |
| `src/kontra/state/backends/s3.py` | Implement `get_history()` |
| `src/kontra/api/__init__.py` or `src/kontra/__init__.py` | Add `kontra.get_history()` Python API |
| `tests/test_history.py` | New test file |
| `docs/advanced/state-and-diff.md` | Document history command |

### State Backend Changes

```python
# base.py
class StateBackend(ABC):
    @abstractmethod
    def get_history(
        self,
        contract_fingerprint: str,
        since: Optional[datetime] = None,
        limit: int = 20,
        failed_only: bool = False,
    ) -> List[RunSummary]:
        """Get validation history for a contract."""
        pass

@dataclass
class RunSummary:
    run_id: str
    timestamp: datetime
    passed: bool
    failed_count: int
    total_rows: Optional[int]
```

### Implementation Steps

- [ ] Define `RunSummary` dataclass in `state/types.py`
- [ ] Add `get_history()` abstract method to `StateBackend`
- [ ] Implement `get_history()` in `LocalStore`
- [ ] Implement `get_history()` in `PostgresStore`
- [ ] Implement `get_history()` in `S3Store`
- [ ] Add `kontra history` CLI command
- [ ] Add `kontra.get_history()` Python API
- [ ] Add Rich table reporter for history
- [ ] Add JSON output for history
- [ ] Write tests
- [ ] Update docs

### Testing

```python
def test_history_returns_recent_runs(tmp_path):
    """Verify history returns runs in reverse chronological order."""
    store = LocalStore(tmp_path)

    # Create some runs
    for i in range(5):
        store.save_run(make_run(passed=(i % 2 == 0)))

    history = store.get_history("fingerprint", limit=3)

    assert len(history) == 3
    assert history[0].timestamp > history[1].timestamp  # Reverse chrono
```

### Estimated Effort

**Low-medium** (half day to full day)

---

## Implementation Order

1. **`storage_options`** — Unblocks cloud users, low risk
2. **`kontra history`** — Quick win, demonstrates state value
3. **Custom SQL pushdown** — Higher complexity, do last

## Total Estimated Effort

- storage_options: 0.5-1 day
- history: 0.5-1 day
- custom SQL pushdown: 1-2 days

**Total: 2-4 days**

---

## Progress Tracking

### storage_options ✅ COMPLETE
- [x] Add param to `validate()` signature
- [x] Add param to `profile()` signature
- [x] Pass through engine to materializers (via DatasetHandle.fs_opts)
- [x] Update DatasetHandle.from_uri() to merge storage_options
- [x] Add CLI flag (`--storage-options` on validate and profile)
- [x] Write tests (11 tests in test_storage_options.py)
- [ ] Update docs (deferred to end)

### history ✅ COMPLETE
- [x] Define `RunSummary` type in state/types.py
- [x] Add `get_run_summaries()` to state backends (base class with default impl)
- [x] LocalStore uses default implementation
- [x] PostgresStore/S3Store use default implementation
- [x] Add `kontra history` CLI command
- [x] Add `kontra.get_history()` Python API
- [x] Write tests (14 tests in test_history.py)
- [ ] Update docs (deferred to end)

### custom SQL pushdown
- [ ] Add `supports_remote_execution()` to rule
- [ ] Add `to_remote_sql()` method
- [ ] Update PostgreSQL executor
- [ ] Update SQL Server executor
- [ ] Add routing in engine
- [ ] Add fallback logic
- [ ] Write tests
- [ ] Update docs

---

## Open Questions

1. **GCS support**: Include in `storage_options` now, or defer?
2. **History aggregations**: Should history show per-rule breakdown, or just run-level?
3. **Custom SQL security**: Any guardrails, or pure pass-through?

---

*Created: 2026-01-23*
